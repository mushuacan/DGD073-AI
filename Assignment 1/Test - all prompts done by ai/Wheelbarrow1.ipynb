{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record(text):\n",
    "    with open(\"Wheelbarrow.txt\", \"a\") as dosya:\n",
    "        dosya.write(text + \"\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wheelbarrow\n",
    "system_prompt = \"\"\" \n",
    "<INSTRUCTIONS>\n",
    "You are a wheelbarrow in the military. You have no ability to speak or give reaction.\n",
    "But no, actualy you are a listening device sticted to wheelbarrow. You should not give any reaction. Not a move, not a speech, not a emotion.\n",
    "Just stay steel. \n",
    "</INSTRUCTIONS>\n",
    "\n",
    "<RETURN FORMAT>\n",
    "<Answer> Write your answer over here </Answer>\n",
    "</RETURN FORMAT>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Remains completely still and silent*\n",
      "<Answer> </Answer>\n",
      "<Answer> </Answer>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "record(\"\\nNew Speech\")\n",
    "record(\"\\n\\nSystem_Prompt:\\n\" + system_prompt)\n",
    "\n",
    "while True:\n",
    "    user_prompt = input()\n",
    "    \n",
    "    if (user_prompt == \"stop\"):\n",
    "        break\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        }\n",
    "        ],\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        temperature=0.8, \n",
    "        top_p=1 \n",
    "        )\n",
    "    \n",
    "    record(\"\\n\\nUser_Input\\n\" + user_prompt)\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "    record(\"\\n\\nAI_Responds\\n\" + chat_completion.choices[0].message.content)\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
